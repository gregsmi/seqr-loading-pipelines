FROM bitnami/minideb:buster

LABEL maintainer="Microsoft Health Futures"

# install commmon utilities
RUN install_packages \
    ca-certificates \
    less \
    nano \
    wget \
    curl \
    g++ \
    git \
    htop \
    make \
    autoconf \
    unzip \
    bzip2 \
    zlib1g-dev \
    dpkg-dev \
    build-essential \
    libcurl4-openssl-dev \
    libbz2-dev \
    liblzma-dev

# install java-11 (version depends on base image)
RUN install_packages default-jdk

RUN apt-get update \
	&& apt-get dist-upgrade -y \
	&& apt-get install -y --no-install-recommends python-smbus libncursesw5-dev libgdbm-dev libc6-dev zlib1g-dev libsqlite3-dev libssl-dev openssl libffi-dev \
	&& apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# install python3.9
ENV PYTHON_VERSION="3.9.1"
RUN wget https://www.python.org/ftp/python/${PYTHON_VERSION}/Python-${PYTHON_VERSION}.tar.xz \
	&& tar xvf Python-${PYTHON_VERSION}.tar.xz \
	&& rm Python-${PYTHON_VERSION}.tar.xz
WORKDIR /Python-${PYTHON_VERSION}
RUN ./configure --enable-optimizations \
    && make install \
    && make clean
WORKDIR /

# install Hail
RUN python3 -m pip install --upgrade pip
RUN python3 -m pip install --no-cache-dir -U crcmod
RUN python3 -m pip install hail

# Add jars required to support ABFS
RUN SPARK_HOME=/usr/local/lib/python3.9/site-packages/pyspark && \
    curl -sSL https://search.maven.org/remotecontent?filepath=org/apache/hadoop/hadoop-azure/3.2.2/hadoop-azure-3.2.2.jar \
     > $SPARK_HOME/jars/hadoop-azure-3.2.2.jar && \
    curl -sSL https://search.maven.org/remotecontent?filepath=com/microsoft/azure/azure-storage/7.0.0/azure-storage-7.0.0.jar \
     > $SPARK_HOME/jars/azure-storage-7.0.0.jar && \
    curl -sSL https://search.maven.org/remotecontent?filepath=org/eclipse/jetty/jetty-util-ajax/9.4.20.v20190813/jetty-util-ajax-9.4.20.v20190813.jar \
     > $SPARK_HOME/jars/jetty-util-ajax-9.4.20.v20190813.jar && \
    curl -sSL https://search.maven.org/remotecontent?filepath=org/eclipse/jetty/jetty-util/9.4.20.v20190813/jetty-util-9.4.20.v20190813.jar \
     > $SPARK_HOME/jars/jetty-util-9.4.20.v20190813.jar && \
    curl -sSL https://repo1.maven.org/maven2/org/apache/hadoop/thirdparty/hadoop-shaded-guava/1.1.1/hadoop-shaded-guava-1.1.1.jar \
     > $SPARK_HOME/jars/hadoop-shaded-guava-1.1.1.jar && \
    curl -sSL https://repo1.maven.org/maven2/org/wildfly/openssl/wildfly-openssl/2.2.5.Final/wildfly-openssl-2.2.5.Final.jar \
     > $SPARK_HOME/jars/wildfly-openssl-2.2.5.Final.jar
# Run container with "-v ./spark-config:/spark-config" and fill in core-sites.xml with necessary 
# ABFS authentication settings/secrets. Tell Spark to use this mounted directory for configuration.
ENV SPARK_CONF_DIR=/spark-config

# install htslib
ENV SAMTOOLS_VERSION="1.9"
RUN wget https://github.com/samtools/htslib/releases/download/${SAMTOOLS_VERSION}/htslib-${SAMTOOLS_VERSION}.tar.bz2 \
	&& tar xjf htslib-${SAMTOOLS_VERSION}.tar.bz2 \
	&& rm htslib-${SAMTOOLS_VERSION}.tar.bz2
WORKDIR htslib-${SAMTOOLS_VERSION}
RUN ./configure \
	&& make \
	&& make install \
	&& make clean
WORKDIR /

# install VEP dependencies
RUN wget https://raw.github.com/miyagawa/cpanminus/master/cpanm -O /usr/bin/cpanm && chmod +x /usr/bin/cpanm
ENV VEP_VERSION="99"
RUN wget https://github.com/Ensembl/ensembl-vep/archive/release/${VEP_VERSION}.zip \
    && unzip ${VEP_VERSION}.zip \
    && rm ${VEP_VERSION}.zip

RUN /usr/bin/cpanm --notest Module::Build
RUN /usr/bin/cpanm --notest Set::IntervalTree
RUN /usr/bin/cpanm --notest PerlIO::gzip
RUN /usr/bin/cpanm --notest DBI
RUN /usr/bin/cpanm --notest CGI
RUN /usr/bin/cpanm --notest JSON
RUN /usr/bin/cpanm --notest Try::Tiny
# LoFTEE dependencies
RUN /usr/bin/cpanm --notest DBD::SQLite
RUN /usr/bin/cpanm --notest  List::MoreUtils

# install VEP
WORKDIR /ensembl-vep-release-${VEP_VERSION}
RUN perl INSTALL.pl -a ap -n -l -g all
RUN ln -s /ensembl-vep-release-${VEP_VERSION}/vep /vep

WORKDIR /seqr-loading-pipelines
COPY requirements.txt .
RUN python3 -m pip install -r ./requirements.txt

# copy files from seqr-loading-pipelines repo
COPY hail_builds/ ./hail_builds
COPY hail_scripts/ ./hail_scripts
COPY luigi_pipeline/ ./luigi_pipeline

COPY docker/vep_configs/* /vep_configs/

COPY docker/bashrc /root/.bashrc
COPY docker/gitconfig /root/.gitconfig
COPY docker/bin/*.sh /usr/local/bin/

ENV PATH=/usr/local/lib/python3.9/site-packages/pyspark/bin:$PATH
ENV PYTHONPATH=".:/seqr-loading-pipelines:/seqr-loading-pipelines/luigi_pipeline"

COPY docker/entrypoint.sh /

WORKDIR /

CMD [ "/entrypoint.sh" ]
